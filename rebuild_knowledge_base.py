#!/usr/bin/env python3
"""
é‡æ–°æ„å»ºå®Œæ•´çš„å‘é‡çŸ¥è¯†åº“
"""

import os
import sys
from pdf_processor import PDFProcessor
from vector_store import VectorStore
from config import Config

def rebuild_knowledge_base():
    """é‡æ–°æ„å»ºçŸ¥è¯†åº“"""
    print("ğŸ”„ å¼€å§‹é‡æ–°æ„å»ºçŸ¥è¯†åº“...")
    print("=" * 50)
    
    # 1. å¤„ç†PDFæ–‡æ¡£
    print("ğŸ“„ æ­¥éª¤1: å¤„ç†PDFæ–‡æ¡£")
    processor = PDFProcessor(Config.PDF_PATH)
    chunks = processor.process_document()
    
    if not chunks:
        print("âŒ PDFå¤„ç†å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
        return False
    
    print(f"âœ… PDFå¤„ç†å®Œæˆï¼Œè·å¾— {len(chunks)} ä¸ªæ–‡æœ¬å—")
    
    # 2. æ„å»ºå‘é‡æ•°æ®åº“
    print("\nğŸ” æ­¥éª¤2: æ„å»ºå‘é‡æ•°æ®åº“")
    vector_store = VectorStore()
    
    try:
        vector_store.add_chunks(chunks)
        print("âœ… å‘é‡åŒ–å®Œæˆ")
        
        # 3. ä¿å­˜å‘é‡æ•°æ®åº“
        print("\nğŸ’¾ æ­¥éª¤3: ä¿å­˜å‘é‡æ•°æ®åº“")
        vector_store.save()
        
        # 4. æµ‹è¯•æœç´¢åŠŸèƒ½
        print("\nğŸ§ª æ­¥éª¤4: æµ‹è¯•æœç´¢åŠŸèƒ½")
        test_queries = [
            "çº¿ä¸‹åº—é€‰å€",
            "æˆæœ¬æ§åˆ¶",
            "ç°é‡‘æµç®¡ç†",
            "é£é™©å¤„ç†",
            "å¤šåº—å¤åˆ¶"
        ]
        
        for query in test_queries:
            results = vector_store.search(query, top_k=3)
            print(f"ğŸ” æŸ¥è¯¢: '{query}' -> æ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
            if results:
                best_match = results[0]
                preview = best_match[0]['text'][:80] + "..." if len(best_match[0]['text']) > 80 else best_match[0]['text']
                print(f"   æœ€ä½³åŒ¹é…: {preview}")
        
        # 5. æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  æ–‡æ¡£å—æ•°é‡: {len(vector_store.chunks)}")
        print(f"  å‘é‡æ•°é‡: {len(vector_store.vectors)}")
        print(f"  å‘é‡ç»´åº¦: {len(vector_store.vectors[0]) if vector_store.vectors else 0}")
        
        # è®¡ç®—å¹³å‡å—é•¿åº¦
        if vector_store.chunks:
            avg_length = sum(len(chunk['text']) for chunk in vector_store.chunks) / len(vector_store.chunks)
            print(f"  å¹³å‡å—é•¿åº¦: {avg_length:.1f} å­—ç¬¦")
        
        print("\nâœ… çŸ¥è¯†åº“é‡å»ºå®Œæˆï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æ„å»ºçŸ¥è¯†åº“å¤±è´¥: {e}")
        return False

def test_knowledge_base():
    """æµ‹è¯•çŸ¥è¯†åº“åŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•çŸ¥è¯†åº“åŠŸèƒ½...")
    
    try:
        vector_store = VectorStore()
        
        # æµ‹è¯•åŠ è½½
        if vector_store.load():
            print("âœ… çŸ¥è¯†åº“åŠ è½½æˆåŠŸ")
            
            # æµ‹è¯•æœç´¢
            test_query = "çº¿ä¸‹åº—é€‰å€æœ‰ä»€ä¹ˆæ³¨æ„äº‹é¡¹"
            results = vector_store.search(test_query, top_k=5)
            
            print(f"ğŸ” æµ‹è¯•æŸ¥è¯¢: '{test_query}'")
            print(f"ğŸ“Š æœç´¢ç»“æœ: {len(results)} ä¸ª")
            
            for i, (chunk, score) in enumerate(results[:3], 1):
                preview = chunk['text'][:100] + "..." if len(chunk['text']) > 100 else chunk['text']
                print(f"  {i}. ç›¸ä¼¼åº¦ {score:.3f}: {preview}")
            
            return True
        else:
            print("âŒ çŸ¥è¯†åº“åŠ è½½å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ çŸ¥è¯†åº“æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ é‡æ–°æ„å»ºæ•™åŸ¹ç®¡å®¶çŸ¥è¯†åº“")
    print("=" * 50)
    
    # é‡å»ºçŸ¥è¯†åº“
    if rebuild_knowledge_base():
        print("\n" + "=" * 50)
        
        # æµ‹è¯•çŸ¥è¯†åº“
        if test_knowledge_base():
            print("\nğŸ‰ çŸ¥è¯†åº“é‡å»ºå’Œæµ‹è¯•å…¨éƒ¨æˆåŠŸï¼")
            print("ğŸ’¡ ç°åœ¨å¯ä»¥å¯åŠ¨åº”ç”¨ä½¿ç”¨æ–°çš„çŸ¥è¯†åº“äº†")
        else:
            print("\nâš ï¸ çŸ¥è¯†åº“é‡å»ºæˆåŠŸä½†æµ‹è¯•å¤±è´¥")
    else:
        print("\nâŒ çŸ¥è¯†åº“é‡å»ºå¤±è´¥")

if __name__ == "__main__":
    main()
